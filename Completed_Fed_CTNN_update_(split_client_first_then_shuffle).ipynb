{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andre-Hua/Andre-Hua/blob/main/Completed_Fed_CTNN_update_(split_client_first_then_shuffle).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPBbTlVrSFA"
      },
      "source": [
        "## Load Library and Data Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iU0-dLlhq6Ug"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, \\\n",
        "    precision_recall_fscore_support, roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Activation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TNN library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, concatenate\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, \\\n",
        "    precision_recall_fscore_support, roc_auc_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, MultiHeadAttention, Flatten, Add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, confusion_matrix\n",
        "\n",
        "\n",
        "from tensorflow.python.ops.parallel_for.pfor import def_function\n",
        "\n",
        "\n",
        "# plot library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSM4Du-BrLk1",
        "outputId": "946708ef-7568-475e-f657-71ab776bf56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "       Unnamed: 0        c1        c2        c3        c4        c5        c6  \\\n",
            "0               0  0.208787  0.062782  0.062782  0.106584  0.063512  0.168636   \n",
            "1               1  0.210726  0.359244  0.066872  0.067650  0.109639  0.171846   \n",
            "2               2  0.051645  0.160217  0.068664  0.049884  0.062209  0.075707   \n",
            "3               3  0.161297  0.043674  0.075437  0.043178  0.043674  0.138467   \n",
            "4               4  0.024164  0.039566  0.022837  0.023102  0.038504  0.055498   \n",
            "...           ...       ...       ...       ...       ...       ...       ...   \n",
            "53599       53599  1.333000  1.070000  0.938000  0.900000  0.819000  0.317000   \n",
            "53600       53600  3.155000  1.892000  2.177000  0.715000  0.405000  0.071000   \n",
            "53601       53601  1.278000  1.149000  0.879000  0.955000  0.715000  0.065000   \n",
            "53602       53602  1.434000  1.050000  0.864000  1.038000  0.133000  0.072000   \n",
            "53603       53603  1.092000  1.420000  1.304000  1.060000  0.980000  0.472000   \n",
            "\n",
            "             c7        c8        c9  ...       c17       c18       c19  \\\n",
            "0      0.099283  0.062782  0.076653  ...  0.062782  0.088333  0.086143   \n",
            "1      0.068427  0.113527  0.066095  ...  0.097976  0.068427  0.118193   \n",
            "2      0.050471  0.062796  0.067490  ...  0.057514  0.051058  0.061622   \n",
            "3      0.056082  0.042682  0.073948  ...  0.041689  0.047645  0.075933   \n",
            "4      0.028148  0.037176  0.023102  ...  0.023368  0.023368  0.040894   \n",
            "...         ...       ...       ...  ...       ...       ...       ...   \n",
            "53599  0.188000  0.072000  0.142000  ...  5.126000  1.352000  0.331000   \n",
            "53600  0.067000  0.220000  0.067000  ...  0.102000  0.374000  0.103000   \n",
            "53601  0.204000  0.065000  0.065000  ...  1.366000  0.294000  0.034000   \n",
            "53602  0.175000  0.072000  0.191000  ...  1.381000  0.159000  0.109000   \n",
            "53603  0.447000  0.229000  0.075000  ...  0.187000  0.037000  0.037000   \n",
            "\n",
            "            c20       c21       c22       c23       c24  Type  Label  \n",
            "0      0.159145  0.085413  0.091253  0.064972  0.081033     1      1  \n",
            "1      0.327363  0.067650  0.100308  0.112750  0.067650     1      1  \n",
            "2      0.343908  0.058101  0.051058  0.065730  0.085097     1      1  \n",
            "3      0.111667  0.213408  0.064022  0.063526  0.043178     1      1  \n",
            "4      0.024695  0.023368  0.034255  0.033458  0.023368     1      1  \n",
            "...         ...       ...       ...       ...       ...   ...    ...  \n",
            "53599  0.098000  0.240000  0.339000  0.900000  5.051000     0      0  \n",
            "53600  0.133000  1.577000  3.016000  1.237000  2.403000     0      0  \n",
            "53601  0.259000  0.110000  3.155000  1.446000  0.910000     0      0  \n",
            "53602  0.044000  0.038000  0.339000  0.178000  4.818000     0      0  \n",
            "53603  4.970000  3.117000  4.509000  3.093000  1.804000     0      0  \n",
            "\n",
            "[53604 rows x 27 columns]\n",
            "       Unnamed: 0        c1        c2        c3        c4        c5        c6  \\\n",
            "0               0  0.095460  0.082576  0.058272  0.065007  0.083455  0.063836   \n",
            "1               1  0.231441  0.135672  0.095769  0.115358  0.195891  0.515120   \n",
            "2               2  0.072578  0.233612  0.190518  0.144401  0.145913  0.204883   \n",
            "3               3  0.412730  0.137946  0.152350  0.156228  0.125758  0.153458   \n",
            "4               4  0.294744  0.358851  0.307271  0.257901  0.156214  0.112740   \n",
            "...           ...       ...       ...       ...       ...       ...       ...   \n",
            "53599       53599  0.238000  0.930000  1.204000  0.036000  0.060000  0.065000   \n",
            "53600       53600  0.265000  0.232000  0.981000  0.068000  0.038000  0.041000   \n",
            "53601       53601  0.249000  1.036000  0.919000  0.258000  0.078000  0.038000   \n",
            "53602       53602  0.290000  0.247000  0.613000  0.049000  0.068000  0.067000   \n",
            "53603       53603  0.202000  0.349000  0.651000  0.351000  0.064000  0.067000   \n",
            "\n",
            "             c7        c8        c9  ...       c17       c18       c19  \\\n",
            "0      0.059150  0.035139  0.660024  ...  0.110980  0.071742  0.386234   \n",
            "1      0.125515  0.101573  0.211852  ...  0.081984  0.047884  0.061669   \n",
            "2      0.142889  0.093747  0.425642  ...  1.589165  0.482344  0.949567   \n",
            "3      0.121326  0.130190  0.122988  ...  0.099720  0.767845  0.229356   \n",
            "4      0.136319  0.170215  0.263059  ...  0.504012  1.788359  0.772966   \n",
            "...         ...       ...       ...  ...       ...       ...       ...   \n",
            "53599  0.038000  0.036000  0.041000  ...  0.842000  0.093000  0.482000   \n",
            "53600  0.038000  0.064000  0.066000  ...  0.767000  0.605000  1.439000   \n",
            "53601  0.044000  0.038000  0.043000  ...  1.383000  0.100000  0.233000   \n",
            "53602  0.065000  0.078000  0.065000  ...  1.620000  0.285000  1.167000   \n",
            "53603  0.068000  0.121000  0.063000  ...  2.391000  0.796000  1.216000   \n",
            "\n",
            "            c20       c21       c22       c23       c24  Type  Label  \n",
            "0      0.121815  0.140262  0.146705  0.161053  0.148754     1      1  \n",
            "1      0.340269  0.235069  0.264090  0.176302  0.144379     1      1  \n",
            "2      0.258561  0.199591  1.099260  0.222271  0.593480     1      1  \n",
            "3      0.717430  0.160106  0.328522  0.327414  0.293620     1      1  \n",
            "4      2.495744  0.358114  1.491404  0.468643  0.436958     1      1  \n",
            "...         ...       ...       ...       ...       ...   ...    ...  \n",
            "53599  0.196000  0.232000  0.191000  0.408000  0.199000     0      0  \n",
            "53600  0.678000  0.602000  0.246000  0.523000  0.529000     0      0  \n",
            "53601  0.683000  1.243000  1.637000  0.578000  0.202000     0      0  \n",
            "53602  0.631000  0.352000  0.592000  0.212000  0.206000     0      0  \n",
            "53603  0.383000  0.300000  0.255000  0.907000  0.212000     0      0  \n",
            "\n",
            "[53604 rows x 27 columns]\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "df1 = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/FYP/data/df_100u_535d_24ppd_15%_client1.csv\")\n",
        "df2 = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/FYP/data/df_100u_535d_24ppd_15%_client2.csv\")\n",
        "df3 = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/FYP/data/df_100u_535d_24ppd_15%_client3.csv\")\n",
        "\n",
        "# df1 = df1.iloc[1:] # drop the first row\n",
        "# df2 = df2.iloc[1:] # drop the first row\n",
        "# df3 = df3.iloc[1:] # drop the first row\n",
        "\n",
        "# print(\"df1: \", df1)\n",
        "# print(\"df2: \", df2)\n",
        "\n",
        "# df1.pop(df1.columns[0]) # drop the first column (i.e. the wrong index column)\n",
        "# df2.pop(df2.columns[0]) # drop the first column (i.e. the wrong index column)\n",
        "# df3.pop(df3.columns[0]) # drop the first column (i.e. the wrong index column)\n",
        "\n",
        "# print(\"df1: \", df1)\n",
        "# print(\"df2: \", df2)\n",
        "\n",
        "print(df1)\n",
        "print(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve6KAl-rrXpc"
      },
      "source": [
        "## Create train and test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lF8N5Kj0DqJ"
      },
      "source": [
        "### Split into train and test dataset for each client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DrzsJPXE3C97"
      },
      "outputs": [],
      "source": [
        "def read_data(X, y, train_size):\n",
        "\n",
        "    # Splitting the dataset into training set and test set\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_size, random_state = None, shuffle = True, stratify = None)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_size, random_state = None, shuffle = True, stratify = y)\n",
        "    # no need to shuffle again as df has been shuffled previously\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pAcgrORy3IJN"
      },
      "outputs": [],
      "source": [
        "train_size = 0.6  # percentage of the test size comparing to the whole dataset\n",
        "\n",
        "X1 = df1.iloc[:, 0:24] # drop the Type and Label column\n",
        "y1 = df1['Label']\n",
        "\n",
        "X2 = df2.iloc[:, 0:24] # drop the Type and Label column\n",
        "y2 = df2['Label']\n",
        "\n",
        "X3 = df3.iloc[:, 0:24] # drop the Type and Label column\n",
        "y3 = df3['Label']\n",
        "\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = read_data(X1, y1, train_size)\n",
        "X_train2, X_test2, y_train2, y_test2 = read_data(X2, y2, train_size)\n",
        "X_train3, X_test3, y_train3, y_test3 = read_data(X3, y3, train_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raO1QCWZ0Mco"
      },
      "source": [
        "### Combine each client's train dataset to get data batch and combine test dataset for global testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfiIuUG40NLA",
        "outputId": "b19a0c26-4da0-492e-f421-2b08b262bcd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0     c1     c2     c3     c4     c5     c6      c7      c8  \\\n",
            "28143       28143  0.739  0.384  0.328  0.377  0.192  0.132   0.171   0.144   \n",
            "46084       46084  1.554  0.326  0.352  1.008  2.233  1.160   0.569   0.518   \n",
            "18790       18790  0.276  0.093  0.414  0.256  0.244  2.239   0.732   0.397   \n",
            "6084         6084  0.856  1.891  0.802  3.656  1.154  1.642   1.612   1.560   \n",
            "10361       10361  4.230  4.254  4.192  4.798  4.107  5.952  17.405  16.002   \n",
            "...           ...    ...    ...    ...    ...    ...    ...     ...     ...   \n",
            "1264         1264  0.000  0.005  0.009  0.000  0.000  0.000   0.000   0.000   \n",
            "4782          762  2.137  2.338  1.706  1.657  2.884  3.068   0.683   0.481   \n",
            "8670         8670  0.867  0.492  1.476  0.869  0.530  0.364   0.855   1.588   \n",
            "25505       25505  0.189  0.198  0.227  0.253  0.271  0.243   1.506   0.624   \n",
            "2639         2639  0.544  0.481  0.417  0.357  0.008  0.018   0.064   0.059   \n",
            "\n",
            "           c9  ...    c14    c15    c16    c17    c18    c19    c20    c21  \\\n",
            "28143   0.138  ...  0.629  0.125  0.174  0.157  0.144  0.149  0.160  0.429   \n",
            "46084   0.913  ...  0.371  0.280  0.269  0.142  0.136  0.218  0.207  0.123   \n",
            "18790   0.262  ...  0.078  0.113  0.166  0.151  0.185  0.237  0.615  0.430   \n",
            "6084    2.072  ...  0.463  0.542  0.479  0.446  0.393  0.563  0.786  0.701   \n",
            "10361  13.605  ...  9.306  8.021  4.838  4.580  4.478  4.701  4.838  4.525   \n",
            "...       ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
            "1264    0.000  ...  0.000  0.000  0.000  0.000  0.000  0.227  0.307  0.161   \n",
            "4782    0.484  ...  0.475  0.643  0.569  0.554  0.556  0.726  0.534  0.546   \n",
            "8670    0.148  ...  0.251  0.639  2.642  0.184  0.104  0.163  0.110  0.154   \n",
            "25505   0.291  ...  0.338  0.673  0.402  0.432  0.550  0.725  0.484  0.603   \n",
            "2639    0.147  ...  0.150  0.208  0.433  0.150  0.147  0.000  0.000  0.000   \n",
            "\n",
            "         c22    c23  \n",
            "28143  0.604  0.635  \n",
            "46084  0.119  0.474  \n",
            "18790  0.327  0.104  \n",
            "6084   1.400  3.107  \n",
            "10361  4.515  4.591  \n",
            "...      ...    ...  \n",
            "1264   0.937  0.486  \n",
            "4782   0.527  0.651  \n",
            "8670   0.103  0.383  \n",
            "25505  1.521  0.526  \n",
            "2639   0.000  0.000  \n",
            "\n",
            "[96486 rows x 24 columns]\n",
            "X_train:         Unnamed: 0     c1     c2     c3     c4     c5     c6      c7      c8  \\\n",
            "28143       28143  0.739  0.384  0.328  0.377  0.192  0.132   0.171   0.144   \n",
            "46084       46084  1.554  0.326  0.352  1.008  2.233  1.160   0.569   0.518   \n",
            "18790       18790  0.276  0.093  0.414  0.256  0.244  2.239   0.732   0.397   \n",
            "6084         6084  0.856  1.891  0.802  3.656  1.154  1.642   1.612   1.560   \n",
            "10361       10361  4.230  4.254  4.192  4.798  4.107  5.952  17.405  16.002   \n",
            "...           ...    ...    ...    ...    ...    ...    ...     ...     ...   \n",
            "1264         1264  0.000  0.005  0.009  0.000  0.000  0.000   0.000   0.000   \n",
            "4782          762  2.137  2.338  1.706  1.657  2.884  3.068   0.683   0.481   \n",
            "8670         8670  0.867  0.492  1.476  0.869  0.530  0.364   0.855   1.588   \n",
            "25505       25505  0.189  0.198  0.227  0.253  0.271  0.243   1.506   0.624   \n",
            "2639         2639  0.544  0.481  0.417  0.357  0.008  0.018   0.064   0.059   \n",
            "\n",
            "           c9  ...    c14    c15    c16    c17    c18    c19    c20    c21  \\\n",
            "28143   0.138  ...  0.629  0.125  0.174  0.157  0.144  0.149  0.160  0.429   \n",
            "46084   0.913  ...  0.371  0.280  0.269  0.142  0.136  0.218  0.207  0.123   \n",
            "18790   0.262  ...  0.078  0.113  0.166  0.151  0.185  0.237  0.615  0.430   \n",
            "6084    2.072  ...  0.463  0.542  0.479  0.446  0.393  0.563  0.786  0.701   \n",
            "10361  13.605  ...  9.306  8.021  4.838  4.580  4.478  4.701  4.838  4.525   \n",
            "...       ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
            "1264    0.000  ...  0.000  0.000  0.000  0.000  0.000  0.227  0.307  0.161   \n",
            "4782    0.484  ...  0.475  0.643  0.569  0.554  0.556  0.726  0.534  0.546   \n",
            "8670    0.148  ...  0.251  0.639  2.642  0.184  0.104  0.163  0.110  0.154   \n",
            "25505   0.291  ...  0.338  0.673  0.402  0.432  0.550  0.725  0.484  0.603   \n",
            "2639    0.147  ...  0.150  0.208  0.433  0.150  0.147  0.000  0.000  0.000   \n",
            "\n",
            "         c22    c23  \n",
            "28143  0.604  0.635  \n",
            "46084  0.119  0.474  \n",
            "18790  0.327  0.104  \n",
            "6084   1.400  3.107  \n",
            "10361  4.515  4.591  \n",
            "...      ...    ...  \n",
            "1264   0.937  0.486  \n",
            "4782   0.527  0.651  \n",
            "8670   0.103  0.383  \n",
            "25505  1.521  0.526  \n",
            "2639   0.000  0.000  \n",
            "\n",
            "[96486 rows x 24 columns]\n",
            "X_test:         Unnamed: 0     c1     c2     c3     c4     c5     c6     c7     c8  \\\n",
            "48302       48302  0.358  0.413  0.392  2.468  0.190  0.207  0.268  0.253   \n",
            "13447       13447  0.620  0.670  0.310  0.072  0.088  0.107  0.107  0.085   \n",
            "50670       50670  0.131  0.079  0.137  0.158  0.136  0.745  0.068  0.125   \n",
            "42873       42873  0.158  0.269  0.260  0.369  0.216  1.641  3.311  2.466   \n",
            "49797       49797  0.100  0.068  0.053  0.064  0.057  0.196  1.670  1.525   \n",
            "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
            "30336       30336  0.264  0.311  2.056  0.660  3.534  1.495  0.446  1.162   \n",
            "20747       20747  0.454  0.318  0.302  0.324  0.492  0.364  0.302  0.279   \n",
            "42282       42282  0.105  1.681  1.606  0.847  0.203  0.203  0.253  0.208   \n",
            "19936       19936  0.589  0.424  0.423  0.283  0.136  0.168  0.135  0.164   \n",
            "41882       41882  0.686  0.091  0.119  0.977  0.086  0.103  0.118  0.086   \n",
            "\n",
            "          c9  ...    c14    c15    c16    c17    c18    c19    c20    c21  \\\n",
            "48302  0.107  ...  0.228  0.633  0.539  0.443  0.094  0.107  0.096  0.085   \n",
            "13447  0.074  ...  0.201  0.071  0.012  0.248  0.022  0.137  0.129  0.460   \n",
            "50670  0.122  ...  0.511  0.785  0.853  0.595  2.286  0.689  0.853  0.877   \n",
            "42873  1.951  ...  0.289  0.595  0.540  0.457  3.695  0.303  0.171  0.905   \n",
            "49797  0.840  ...  2.567  0.414  0.160  0.150  0.160  0.194  0.478  0.118   \n",
            "...      ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
            "30336  1.520  ...  0.117  0.096  0.140  0.085  0.049  0.171  0.218  0.300   \n",
            "20747  0.942  ...  0.171  0.156  0.208  0.129  0.173  0.210  0.255  0.237   \n",
            "42282  0.219  ...  0.229  0.187  0.626  0.224  0.890  0.304  1.293  0.200   \n",
            "19936  1.005  ...  0.433  0.486  0.403  0.294  0.158  0.182  0.150  0.151   \n",
            "41882  0.694  ...  0.092  0.082  0.123  0.905  0.084  0.251  0.143  0.107   \n",
            "\n",
            "         c22    c23  \n",
            "48302  0.099  0.109  \n",
            "13447  0.529  0.582  \n",
            "50670  0.606  0.076  \n",
            "42873  0.165  0.189  \n",
            "49797  0.126  0.114  \n",
            "...      ...    ...  \n",
            "30336  0.399  0.617  \n",
            "20747  1.426  0.849  \n",
            "42282  0.320  0.099  \n",
            "19936  0.140  0.156  \n",
            "41882  0.092  1.096  \n",
            "\n",
            "[64326 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "X_train = pd.concat([X_train1, X_train2, X_train3])\n",
        "print(X_train)\n",
        "\n",
        "y_train = pd.concat([y_train1, y_train2, y_train3])\n",
        "\n",
        "X_test = pd.concat([X_test1, X_test2, X_test3])\n",
        "\n",
        "y_test = pd.concat([y_test1, y_test2, y_test3])\n",
        "\n",
        "print(\"X_train: \", X_train)\n",
        "print(\"X_test: \", X_test)\n",
        "\n",
        "# label_list = df['Label']\n",
        "\n",
        "# data_list = df.iloc[:, 0:24]\n",
        "\n",
        "\n",
        "# print(data_list)\n",
        "# print(label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_WTVzE-4xR1",
        "outputId": "b919ef53-bafb-4e04-e635-241c7b6a053f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train:  28143    0\n",
            "46084    0\n",
            "18790    0\n",
            "6084     0\n",
            "10361    0\n",
            "        ..\n",
            "1264     1\n",
            "4782     1\n",
            "8670     0\n",
            "25505    0\n",
            "2639     1\n",
            "Name: Label, Length: 96486, dtype: int64\n",
            "y_test:  48302    0\n",
            "13447    0\n",
            "50670    0\n",
            "42873    0\n",
            "49797    0\n",
            "        ..\n",
            "30336    0\n",
            "20747    0\n",
            "42282    0\n",
            "19936    0\n",
            "41882    0\n",
            "Name: Label, Length: 64326, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"y_train: \", y_train)\n",
        "print(\"y_test: \", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gslu3Ghq2XKF",
        "outputId": "2b0c67b9-1eea-4780-83f1-fc4786603d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  [[[2.8143e+04]\n",
            "  [7.3900e-01]\n",
            "  [3.8400e-01]\n",
            "  ...\n",
            "  [4.2900e-01]\n",
            "  [6.0400e-01]\n",
            "  [6.3500e-01]]\n",
            "\n",
            " [[4.6084e+04]\n",
            "  [1.5540e+00]\n",
            "  [3.2600e-01]\n",
            "  ...\n",
            "  [1.2300e-01]\n",
            "  [1.1900e-01]\n",
            "  [4.7400e-01]]\n",
            "\n",
            " [[1.8790e+04]\n",
            "  [2.7600e-01]\n",
            "  [9.3000e-02]\n",
            "  ...\n",
            "  [4.3000e-01]\n",
            "  [3.2700e-01]\n",
            "  [1.0400e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[8.6700e+03]\n",
            "  [8.6700e-01]\n",
            "  [4.9200e-01]\n",
            "  ...\n",
            "  [1.5400e-01]\n",
            "  [1.0300e-01]\n",
            "  [3.8300e-01]]\n",
            "\n",
            " [[2.5505e+04]\n",
            "  [1.8900e-01]\n",
            "  [1.9800e-01]\n",
            "  ...\n",
            "  [6.0300e-01]\n",
            "  [1.5210e+00]\n",
            "  [5.2600e-01]]\n",
            "\n",
            " [[2.6390e+03]\n",
            "  [5.4400e-01]\n",
            "  [4.8100e-01]\n",
            "  ...\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]]]\n",
            "X_test:  [[[4.8302e+04]\n",
            "  [3.5800e-01]\n",
            "  [4.1300e-01]\n",
            "  ...\n",
            "  [8.5000e-02]\n",
            "  [9.9000e-02]\n",
            "  [1.0900e-01]]\n",
            "\n",
            " [[1.3447e+04]\n",
            "  [6.2000e-01]\n",
            "  [6.7000e-01]\n",
            "  ...\n",
            "  [4.6000e-01]\n",
            "  [5.2900e-01]\n",
            "  [5.8200e-01]]\n",
            "\n",
            " [[5.0670e+04]\n",
            "  [1.3100e-01]\n",
            "  [7.9000e-02]\n",
            "  ...\n",
            "  [8.7700e-01]\n",
            "  [6.0600e-01]\n",
            "  [7.6000e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[4.2282e+04]\n",
            "  [1.0500e-01]\n",
            "  [1.6810e+00]\n",
            "  ...\n",
            "  [2.0000e-01]\n",
            "  [3.2000e-01]\n",
            "  [9.9000e-02]]\n",
            "\n",
            " [[1.9936e+04]\n",
            "  [5.8900e-01]\n",
            "  [4.2400e-01]\n",
            "  ...\n",
            "  [1.5100e-01]\n",
            "  [1.4000e-01]\n",
            "  [1.5600e-01]]\n",
            "\n",
            " [[4.1882e+04]\n",
            "  [6.8600e-01]\n",
            "  [9.1000e-02]\n",
            "  ...\n",
            "  [1.0700e-01]\n",
            "  [9.2000e-02]\n",
            "  [1.0960e+00]]]\n",
            "y_train:  [0 0 0 ... 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "X_train.reset_index(inplace=True, drop=True)\n",
        "y_train.reset_index(inplace=True, drop=True)\n",
        "X_test.reset_index(inplace=True, drop=True)\n",
        "y_test.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Split the data into input and target variables\n",
        "X_train = X_train.values\n",
        "X_test= X_test.values\n",
        "\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "print(\"X_train: \", X_train)\n",
        "print(\"X_test: \", X_test)\n",
        "print(\"y_train: \", y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOQYcWl02mYx"
      },
      "source": [
        "## Fed Avg Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Yxduzy12pXm"
      },
      "outputs": [],
      "source": [
        "# fed avg algorithm for model aggregation\n",
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the bs\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
        "    return local_count/global_count\n",
        "\n",
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights\n",
        "       input: weight\n",
        "       output: final scaled weight'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final\n",
        "\n",
        "\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of all clients' scaled weights. The is equivalent to scaled avg of the weights\n",
        "       input: scaled weight list (i.e. the output of function \"scale_model_weights\" -> weight_final list)\n",
        "       output: the average weights over all clients'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "\n",
        "    return avg_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Trhp5uJohh"
      },
      "source": [
        "## Creating Client that have its own training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MCzf1MbEkYrE"
      },
      "outputs": [],
      "source": [
        "def create_clients(data_list, label_list, X_test, y_test, num_clients, initial='clients'):\n",
        "    \"\"\"\n",
        "    Returns a dictionary with keys as clients' names and values as data shards - tuples of\n",
        "    training data, training labels, test data, and test labels.\n",
        "\n",
        "    Args:\n",
        "        data_list: A list of numpy arrays of training data (consumption data).\n",
        "        label_list: A list of binarized labels for the training data.\n",
        "        X_test: Test features as a numpy array.\n",
        "        y_test: Test labels as a numpy array.\n",
        "        num_clients: Number of federated members (clients).\n",
        "        initial: The clients' name prefix, e.g., 'client_1'.\n",
        "    \"\"\"\n",
        "    # Create a list of client names\n",
        "    client_names = [f'{initial}_{i+1}' for i in range(num_clients)]\n",
        "\n",
        "    # Ensure data_list and label_list are properly shaped arrays\n",
        "    assert len(data_list) == len(label_list), \"Mismatch in lengths of data_list and label_list\"\n",
        "\n",
        "    # Calculate sizes for sharding\n",
        "    total_samples = len(data_list)\n",
        "    size_per_client = total_samples // num_clients\n",
        "\n",
        "    # Shard the training data and labels\n",
        "    clients = {}\n",
        "    for i, client_name in enumerate(client_names):\n",
        "        start_index = i * size_per_client\n",
        "        end_index = start_index + size_per_client\n",
        "        client_data = data_list[start_index:end_index]\n",
        "        client_labels = label_list[start_index:end_index]\n",
        "\n",
        "        # Shard the test data and labels similarly if needed or distribute uniformly\n",
        "        test_start = i * (len(X_test) // num_clients)\n",
        "        test_end = test_start + (len(X_test) // num_clients)\n",
        "\n",
        "        clients[client_name] = {\n",
        "            'train_data': (np.array(client_data), np.array(client_labels)),\n",
        "            'test_data': (X_test[test_start:test_end], y_test[test_start:test_end])\n",
        "        }\n",
        "\n",
        "    return clients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sn3AJjdTWUa"
      },
      "source": [
        "### Create number of local centers (i.e. # of clients)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oinOJ2cYysVG"
      },
      "outputs": [],
      "source": [
        "# Create clients with both training and test data\n",
        "num_clients = 3\n",
        "clients = create_clients(X_train, y_train, X_test, y_test, num_clients=num_clients, initial='client')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbej1CXqh3sW",
        "outputId": "ce69a64a-bd6d-4097-b203-5fb6c5e729b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client: client_1\n",
            "Training data samples:\n",
            "[[[2.8143e+04]\n",
            "  [7.3900e-01]\n",
            "  [3.8400e-01]\n",
            "  [3.2800e-01]\n",
            "  [3.7700e-01]\n",
            "  [1.9200e-01]\n",
            "  [1.3200e-01]\n",
            "  [1.7100e-01]\n",
            "  [1.4400e-01]\n",
            "  [1.3800e-01]\n",
            "  [1.5300e-01]\n",
            "  [1.6600e-01]\n",
            "  [1.2800e-01]\n",
            "  [3.1300e-01]\n",
            "  [6.2900e-01]\n",
            "  [1.2500e-01]\n",
            "  [1.7400e-01]\n",
            "  [1.5700e-01]\n",
            "  [1.4400e-01]\n",
            "  [1.4900e-01]\n",
            "  [1.6000e-01]\n",
            "  [4.2900e-01]\n",
            "  [6.0400e-01]\n",
            "  [6.3500e-01]]\n",
            "\n",
            " [[4.6084e+04]\n",
            "  [1.5540e+00]\n",
            "  [3.2600e-01]\n",
            "  [3.5200e-01]\n",
            "  [1.0080e+00]\n",
            "  [2.2330e+00]\n",
            "  [1.1600e+00]\n",
            "  [5.6900e-01]\n",
            "  [5.1800e-01]\n",
            "  [9.1300e-01]\n",
            "  [8.7200e-01]\n",
            "  [9.9700e-01]\n",
            "  [1.8520e+00]\n",
            "  [5.8300e-01]\n",
            "  [3.7100e-01]\n",
            "  [2.8000e-01]\n",
            "  [2.6900e-01]\n",
            "  [1.4200e-01]\n",
            "  [1.3600e-01]\n",
            "  [2.1800e-01]\n",
            "  [2.0700e-01]\n",
            "  [1.2300e-01]\n",
            "  [1.1900e-01]\n",
            "  [4.7400e-01]]]\n",
            "Training labels samples:\n",
            "[0 0]\n",
            "Test data samples:\n",
            "[[[4.8302e+04]\n",
            "  [3.5800e-01]\n",
            "  [4.1300e-01]\n",
            "  [3.9200e-01]\n",
            "  [2.4680e+00]\n",
            "  [1.9000e-01]\n",
            "  [2.0700e-01]\n",
            "  [2.6800e-01]\n",
            "  [2.5300e-01]\n",
            "  [1.0700e-01]\n",
            "  [1.4100e-01]\n",
            "  [1.4100e-01]\n",
            "  [3.0500e-01]\n",
            "  [2.0400e-01]\n",
            "  [2.2800e-01]\n",
            "  [6.3300e-01]\n",
            "  [5.3900e-01]\n",
            "  [4.4300e-01]\n",
            "  [9.4000e-02]\n",
            "  [1.0700e-01]\n",
            "  [9.6000e-02]\n",
            "  [8.5000e-02]\n",
            "  [9.9000e-02]\n",
            "  [1.0900e-01]]\n",
            "\n",
            " [[1.3447e+04]\n",
            "  [6.2000e-01]\n",
            "  [6.7000e-01]\n",
            "  [3.1000e-01]\n",
            "  [7.2000e-02]\n",
            "  [8.8000e-02]\n",
            "  [1.0700e-01]\n",
            "  [1.0700e-01]\n",
            "  [8.5000e-02]\n",
            "  [7.4000e-02]\n",
            "  [1.4200e-01]\n",
            "  [1.1200e-01]\n",
            "  [1.2000e-02]\n",
            "  [1.5000e-02]\n",
            "  [2.0100e-01]\n",
            "  [7.1000e-02]\n",
            "  [1.2000e-02]\n",
            "  [2.4800e-01]\n",
            "  [2.2000e-02]\n",
            "  [1.3700e-01]\n",
            "  [1.2900e-01]\n",
            "  [4.6000e-01]\n",
            "  [5.2900e-01]\n",
            "  [5.8200e-01]]]\n",
            "Test labels samples:\n",
            "[0 0]\n",
            "\n",
            "\n",
            "Client: client_2\n",
            "Training data samples:\n",
            "[[[1.7347e+04]\n",
            "  [3.8060e+00]\n",
            "  [1.1050e+00]\n",
            "  [5.9900e-01]\n",
            "  [6.8000e-01]\n",
            "  [6.9900e-01]\n",
            "  [7.0100e-01]\n",
            "  [2.7900e+00]\n",
            "  [2.3090e+00]\n",
            "  [9.9000e-01]\n",
            "  [2.5590e+00]\n",
            "  [9.9300e-01]\n",
            "  [8.4000e-02]\n",
            "  [9.1000e-02]\n",
            "  [8.9000e-02]\n",
            "  [6.4000e-02]\n",
            "  [1.6100e-01]\n",
            "  [3.0900e-01]\n",
            "  [2.1100e-01]\n",
            "  [1.8400e-01]\n",
            "  [1.2600e-01]\n",
            "  [6.2000e-02]\n",
            "  [7.9000e-02]\n",
            "  [7.7000e-02]]\n",
            "\n",
            " [[3.9456e+04]\n",
            "  [2.6800e-01]\n",
            "  [8.7000e-02]\n",
            "  [1.1000e-02]\n",
            "  [3.2000e-02]\n",
            "  [1.1000e-02]\n",
            "  [1.1000e-02]\n",
            "  [5.9000e-02]\n",
            "  [1.1000e-02]\n",
            "  [5.8600e-01]\n",
            "  [9.1000e-02]\n",
            "  [8.0100e-01]\n",
            "  [1.0800e-01]\n",
            "  [9.2000e-02]\n",
            "  [5.1520e+00]\n",
            "  [1.1700e-01]\n",
            "  [1.9800e-01]\n",
            "  [1.7200e-01]\n",
            "  [8.9000e-02]\n",
            "  [1.2000e-01]\n",
            "  [2.1600e-01]\n",
            "  [9.0000e-02]\n",
            "  [1.0000e-01]\n",
            "  [2.8700e-01]]]\n",
            "Training labels samples:\n",
            "[0 0]\n",
            "Test data samples:\n",
            "[[[3.3874e+04]\n",
            "  [5.8200e-01]\n",
            "  [1.1320e+00]\n",
            "  [2.2690e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [0.0000e+00]\n",
            "  [3.0100e-01]\n",
            "  [2.9500e-01]\n",
            "  [2.6100e-01]\n",
            "  [3.1000e-01]\n",
            "  [2.0400e-01]]\n",
            "\n",
            " [[3.1945e+04]\n",
            "  [2.1300e-01]\n",
            "  [2.8000e-01]\n",
            "  [1.3800e-01]\n",
            "  [1.4300e-01]\n",
            "  [6.4800e-01]\n",
            "  [1.3450e+00]\n",
            "  [5.9900e-01]\n",
            "  [3.9600e-01]\n",
            "  [1.6300e-01]\n",
            "  [3.6700e-01]\n",
            "  [2.7300e-01]\n",
            "  [2.6700e-01]\n",
            "  [6.0100e-01]\n",
            "  [1.5500e-01]\n",
            "  [3.2200e-01]\n",
            "  [1.9700e-01]\n",
            "  [1.3600e-01]\n",
            "  [1.1900e-01]\n",
            "  [1.2700e-01]\n",
            "  [1.3600e-01]\n",
            "  [1.4670e+00]\n",
            "  [1.5200e-01]\n",
            "  [1.3200e-01]]]\n",
            "Test labels samples:\n",
            "[1 0]\n",
            "\n",
            "\n",
            "Client: client_3\n",
            "Training data samples:\n",
            "[[[2.3403e+04]\n",
            "  [1.1000e-01]\n",
            "  [9.5000e-02]\n",
            "  [7.0000e-02]\n",
            "  [4.3900e-01]\n",
            "  [9.8000e-02]\n",
            "  [8.5000e-02]\n",
            "  [2.4100e-01]\n",
            "  [1.2800e-01]\n",
            "  [3.6900e-01]\n",
            "  [3.8000e-01]\n",
            "  [3.6200e-01]\n",
            "  [5.2100e-01]\n",
            "  [1.6600e-01]\n",
            "  [2.3100e-01]\n",
            "  [1.0760e+00]\n",
            "  [1.4890e+00]\n",
            "  [3.8600e-01]\n",
            "  [3.8800e-01]\n",
            "  [2.8400e-01]\n",
            "  [2.6500e-01]\n",
            "  [3.7600e-01]\n",
            "  [2.5200e-01]\n",
            "  [2.5600e-01]]\n",
            "\n",
            " [[1.0913e+04]\n",
            "  [2.3200e-01]\n",
            "  [2.1600e-01]\n",
            "  [2.5000e-01]\n",
            "  [1.0100e-01]\n",
            "  [2.5500e-01]\n",
            "  [6.2200e-01]\n",
            "  [1.3200e-01]\n",
            "  [9.5000e-02]\n",
            "  [3.7800e-01]\n",
            "  [1.1400e-01]\n",
            "  [1.0300e-01]\n",
            "  [1.2000e-01]\n",
            "  [1.0300e-01]\n",
            "  [1.3100e-01]\n",
            "  [1.0100e-01]\n",
            "  [1.2300e-01]\n",
            "  [1.0200e-01]\n",
            "  [1.3830e+00]\n",
            "  [8.9500e-01]\n",
            "  [4.9000e-01]\n",
            "  [3.7300e-01]\n",
            "  [1.1780e+00]\n",
            "  [3.0000e-01]]]\n",
            "Training labels samples:\n",
            "[0 0]\n",
            "Test data samples:\n",
            "[[[4.516e+04]\n",
            "  [5.670e-01]\n",
            "  [5.000e-01]\n",
            "  [2.214e+00]\n",
            "  [6.720e-01]\n",
            "  [8.350e-01]\n",
            "  [7.870e-01]\n",
            "  [1.131e+00]\n",
            "  [1.212e+00]\n",
            "  [3.154e+00]\n",
            "  [3.518e+00]\n",
            "  [1.371e+00]\n",
            "  [1.221e+00]\n",
            "  [8.580e-01]\n",
            "  [2.390e-01]\n",
            "  [1.710e-01]\n",
            "  [1.710e-01]\n",
            "  [2.600e-01]\n",
            "  [2.480e-01]\n",
            "  [2.260e-01]\n",
            "  [2.910e-01]\n",
            "  [4.130e-01]\n",
            "  [9.900e-01]\n",
            "  [3.760e-01]]\n",
            "\n",
            " [[8.508e+03]\n",
            "  [1.370e-01]\n",
            "  [4.060e-01]\n",
            "  [1.225e+00]\n",
            "  [1.940e-01]\n",
            "  [2.520e-01]\n",
            "  [2.470e-01]\n",
            "  [1.550e-01]\n",
            "  [1.860e-01]\n",
            "  [1.820e-01]\n",
            "  [2.120e-01]\n",
            "  [2.130e-01]\n",
            "  [1.095e+00]\n",
            "  [8.040e-01]\n",
            "  [6.370e-01]\n",
            "  [6.160e-01]\n",
            "  [1.490e-01]\n",
            "  [2.140e-01]\n",
            "  [1.050e-01]\n",
            "  [1.650e-01]\n",
            "  [1.090e-01]\n",
            "  [8.600e-02]\n",
            "  [2.450e-01]\n",
            "  [2.380e-01]]]\n",
            "Test labels samples:\n",
            "[0 0]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing out the content in each client to check and debug\n",
        "for client_name, data in clients.items():\n",
        "    # Print client name\n",
        "    print(f\"Client: {client_name}\")\n",
        "\n",
        "    # Print a small portion of the training data and labels\n",
        "    print(\"Training data samples:\")\n",
        "    print(data['train_data'][0][:2])  # Print first 2 samples from training data\n",
        "    print(\"Training labels samples:\")\n",
        "    print(data['train_data'][1][:2])  # Print first 2 labels from training data\n",
        "\n",
        "    # Print a small portion of the test data and labels\n",
        "    print(\"Test data samples:\")\n",
        "    print(data['test_data'][0][:2])  # Print first 2 samples from test data\n",
        "    print(\"Test labels samples:\")\n",
        "    print(data['test_data'][1][:2])  # Print first 2 labels from test data\n",
        "    print(\"\\n\")  # Print newline for better readability between clients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUCbq6cEHffv"
      },
      "source": [
        "## Data batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3F29CqnbHibe"
      },
      "outputs": [],
      "source": [
        "def batch_client_data(client_data, batch_size=32):\n",
        "    \"\"\"Batch both training and test data for a client.\n",
        "\n",
        "    Args:\n",
        "        client_data: A dictionary containing 'train_data' and 'test_data' for the client.\n",
        "        batch_size: The batch size for batching the datasets.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing batched 'train_dataset' and 'test_dataset'.\n",
        "    \"\"\"\n",
        "    # Batch both training and test data for a client\n",
        "    train_data, train_labels = client_data['train_data']\n",
        "    test_data, test_labels = client_data['test_data']\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels)).shuffle(len(train_labels)).batch(batch_size)\n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels)).batch(batch_size)\n",
        "\n",
        "    return {'train_dataset': train_dataset, 'test_dataset': test_dataset}\n",
        "\n",
        "# Batch data for each client\n",
        "clients_batched = {}\n",
        "for client_name, data in clients.items():\n",
        "    clients_batched[client_name] = batch_client_data(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_udtlujwVUn"
      },
      "source": [
        "# Local Training model (current: CTNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KPAxIOEJmzFr"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Layer Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    # Adding\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    # x = layers.BatchNormalization()(x)  # Add BatchNormalization\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n",
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "    l2_reg=0.01  # L2 regularization factor, adjust as needed\n",
        "    # attention_dropout=0 # Adding dropout to attention mechanism\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        # x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dense(dim, activation=\"relu\", kernel_regularizer=l2(l2_reg))(x)  # L2 regularization added\n",
        "        x = layers.BatchNormalization()(x)  # Add BatchNormalization\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# Learning rate schedule\n",
        "initial_learning_rate = 5e-3\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Dgyg_ieP6u9Z"
      },
      "outputs": [],
      "source": [
        "class CTNN:\n",
        "    def build(shape, classes):\n",
        "        print('-----Transformer Neural Network:')\n",
        "\n",
        "        # Model creation\n",
        "        model = build_model(\n",
        "            input_shape = X_train.shape[1:],\n",
        "            head_size=128,  # change head size from 256 to 128 -> see how training time and acccuracy vary\n",
        "            num_heads=4,\n",
        "            ff_dim=4,\n",
        "            num_transformer_blocks=1,\n",
        "            mlp_units=[128],\n",
        "            mlp_dropout=0.4,\n",
        "            dropout=0.25,\n",
        "            l2_reg=0.01  # L2 regularization factor, adjust as needed\n",
        "            # attention_dropout=0.1\n",
        "        )\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pptIEzt6SlF9"
      },
      "source": [
        "# Global training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "btCHimSmcBLI"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics, weights):\n",
        "    \"\"\"Function to compute the weighted average of performance metrics across all clients\"\"\"\n",
        "    weighted_metrics = {}\n",
        "    total_weight = sum(weights)\n",
        "    for metric in metrics[0].keys():  # Assuming all metrics dicts have the same keys\n",
        "        weighted_sum = sum(metric_value * weight for metric_value, weight in zip([m[metric] for m in metrics], weights))\n",
        "        weighted_metrics[metric] = weighted_sum / total_weight\n",
        "    return weighted_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hF7Ese9o1dk",
        "outputId": "3630fa5c-b8db-4594-f082-a2990acf9508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p6GEmqrXYR5"
      },
      "source": [
        "# Updated version of local_test and global platform for better output print (try it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9_ci2LybXkTv"
      },
      "outputs": [],
      "source": [
        "def local_test(model, test_dataset, client_name, comm_round, batch_size=32):\n",
        "    # Initialize lists to store true labels and predictions\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    # Iterate through the test dataset batches\n",
        "    for X_batch, y_batch in test_dataset:\n",
        "        # Ensure the data is in the correct format and predict\n",
        "        X_batch = tf.cast(X_batch, tf.float32)\n",
        "        y_pred_batch = model.predict(X_batch, verbose=0)  # Suppress verbose output\n",
        "        # Assuming binary classification\n",
        "        y_pred_batch = (y_pred_batch > 0.5).astype(int).flatten()\n",
        "        predictions.extend(y_pred_batch)\n",
        "        true_labels.extend(y_batch.numpy().flatten())\n",
        "\n",
        "    # Calculate and display metrics, ensure metrics are compatible with your labels and predictions\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average = 'weighted')  # Or 'binary' if it's a binary classification\n",
        "    auc = roc_auc_score(true_labels, predictions)\n",
        "    rmse = mean_squared_error(true_labels, predictions, squared = False)\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "    # Format the output\n",
        "    print(f\"Client {client_name} - Round {comm_round}:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"AUC: {auc}\")\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    for row in cm:\n",
        "        print(row)\n",
        "    print(\"\\n\")  # Add an extra newline for better separation\n",
        "\n",
        "    return accuracy, f1, auc, rmse, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsednLV9XqDw",
        "outputId": "d4e7776b-6280-4d3e-d7e0-4a94c5b822a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Transformer Neural Network:\n",
            "-----Transformer Neural Network:\n",
            "Client client_1 - Round 0:\n",
            "Accuracy: 0.9502844883872773\n",
            "F1 Score: 0.9460525750270697\n",
            "AUC: 0.8342661691542288\n",
            "RMSE: 0.22296975492815768\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1066 2150]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_2 - Round 0:\n",
            "Accuracy: 0.9366197183098591\n",
            "F1 Score: 0.9292692883321588\n",
            "AUC: 0.7887126865671642\n",
            "RMSE: 0.25175440748900674\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1359 1857]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_3 - Round 0:\n",
            "Accuracy: 0.9491185523738457\n",
            "F1 Score: 0.9446611123523272\n",
            "AUC: 0.8303793532338308\n",
            "RMSE: 0.22556916373067104\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1091 2125]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_1 - Round 1:\n",
            "Accuracy: 0.940490625874452\n",
            "F1 Score: 0.9341333099297271\n",
            "AUC: 0.8016169154228856\n",
            "RMSE: 0.24394543268023688\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1276 1940]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_2 - Round 1:\n",
            "Accuracy: 0.9374125547989927\n",
            "F1 Score: 0.9302730189703937\n",
            "AUC: 0.7913557213930349\n",
            "RMSE: 0.2501748292714664\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1342 1874]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_3 - Round 1:\n",
            "Accuracy: 0.927198955321332\n",
            "F1 Score: 0.9170285337163357\n",
            "AUC: 0.7573072139303483\n",
            "RMSE: 0.2698166871760678\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1561 1655]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_1 - Round 2:\n",
            "Accuracy: 0.9502844883872773\n",
            "F1 Score: 0.9460525750270697\n",
            "AUC: 0.8342661691542288\n",
            "RMSE: 0.22296975492815768\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1066 2150]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n",
            "Client client_2 - Round 2:\n",
            "Accuracy: 0.9223952989459938\n",
            "F1 Score: 0.910547502491463\n",
            "AUC: 0.7412935323383085\n",
            "RMSE: 0.27857620331608757\n",
            "Confusion Matrix:\n",
            "[18226     0]\n",
            "[1664 1552]\n",
            "\n",
            "\n",
            "-----Transformer Neural Network:\n"
          ]
        }
      ],
      "source": [
        "# Initialize variables for federated training\n",
        "comms_round = 10\n",
        "client_names = list(clients_batched.keys())\n",
        "client_accuracies = {client_name: [] for client_name in client_names}\n",
        "client_rmse = {client_name: [] for client_name in client_names}\n",
        "average_accuracies = []\n",
        "average_rmse = []\n",
        "\n",
        "# Initialize global weights\n",
        "initial_global_model = CTNN()\n",
        "global_weights = initial_global_model.build(X_train.shape[1:]).get_weights()\n",
        "\n",
        "# Start the federated training loop\n",
        "for comm_round in range(comms_round):\n",
        "    scaled_local_weight_list = []\n",
        "    round_accuracies = []\n",
        "    round_rmse = []\n",
        "    local_data_sizes = []\n",
        "\n",
        "    for client_name in client_names:\n",
        "        # Initialize and train local model\n",
        "        smlp_local = CTNN()\n",
        "        local_model = smlp_local.build(X_train.shape[1:])  # Adjust dimensions as necessary\n",
        "        # local_model.compile(loss= 'binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate= 5e-3), metrics= ['accuracy'])\n",
        "        local_model.compile(loss= 'binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr_schedule), metrics= ['accuracy'])\n",
        "        # local_model.compile(loss= 'binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate= 1e-3), metrics= ['accuracy']) # decrease the learning rate to see whether it improves the accuracy dropping situation\n",
        "        # local_model.compile(loss= 'binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate= 5e-4), metrics= ['accuracy'])\n",
        "\n",
        "        # If we have previous global weights, apply them to the local model\n",
        "        if global_weights:\n",
        "            local_model.set_weights(global_weights)\n",
        "\n",
        "        # Fit local model with client's training data\n",
        "        local_model.fit(clients_batched[client_name]['train_dataset'], epochs=2, verbose=0) # increase the lcoal training epoch from 1 to 2 to see the changes\n",
        "\n",
        "        # Perform local testing and get metrics\n",
        "        accuracy, f1, auc, rmse, cm = local_test(local_model, clients_batched[client_name]['test_dataset'], client_name, comm_round)\n",
        "\n",
        "        client_accuracies[client_name].append(accuracy)\n",
        "        client_rmse[client_name].append(rmse)\n",
        "        round_accuracies.append(accuracy)\n",
        "        round_rmse.append(rmse)\n",
        "\n",
        "        # Scale the local model weights for aggregation\n",
        "        local_data_size = list(clients_batched[client_name]['train_dataset'].unbatch().as_numpy_iterator()).__len__()\n",
        "        local_data_sizes.append(local_data_size)\n",
        "        scaling_factor = local_data_size / sum(local_data_sizes)  # Adjust based on actual data size\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        # Clear session to free memory\n",
        "        K.clear_session()\n",
        "\n",
        "    # Update global weights\n",
        "    global_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    # Calculate average metrics for this round and store them\n",
        "    average_accuracies.append(sum(round_accuracies) / len(client_names))\n",
        "    average_rmse.append(sum(round_rmse) / len(client_names))\n",
        "\n",
        "# After all rounds, plot the metrics\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plotting average accuracies\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(comms_round), average_accuracies, marker='x', label='Average Accuracy')\n",
        "for client_name in client_names:\n",
        "    plt.plot(range(comms_round), client_accuracies[client_name], marker='o', linestyle='dashed', label=f'Client {client_name}')\n",
        "plt.title('Average Accuracy vs Client Accuracies over Communication Rounds')\n",
        "plt.xlabel('Communication Rounds')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting average RMSE\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(comms_round), average_rmse, marker='x', label='Average RMSE')\n",
        "for client_name in client_names:\n",
        "    plt.plot(range(comms_round), client_rmse[client_name], marker='o', linestyle='dashed', label=f'Client {client_name}')\n",
        "plt.title('Average RMSE vs Client RMSE over Communication Rounds')\n",
        "plt.xlabel('Communication Rounds')\n",
        "plt.ylabel('RMSE')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKEHgf6q1zZj1mhfxPr2sd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}